# ReaL Reproduction

This is a GPU-friendly, easier reproduction repo for the viewer to reproduce our [ReaL on EDA](https://github.com/airevo2/ReaL_ON_EDA/tree/main?tab=readme-ov-file) result. 

---

## Overview

This repository helps the viewer to reproduce our results. It contains the outputs generated by our 7B model across 27 distinct tasks.

---

## Inputs

* **Prompt file:** `prompt.json`
  Contains the 27 task specifications and corresponding prompt instructions.

---

## Outputs

* **`exported_scripts/`**
  A folder containing the model’s generated OpenROAD scripts.
  All scripts have been verified to run in the OpenROAD Docker environment (see ECE240 Lab 6).
  
## EDA Dataset
   `paired.json` is EDA Model Output for evaluation. 
   
---

## Notices

* You may see warnings when running OpenROAD scripts. These arise because we do not supply full chip‑ and process‑design files (our focus is on EDA functionality, not physical design).
* Our training corpus, extracted from [EDA Corpus](https://github.com/OpenROAD-Assistant/EDA-Corpus) have similar issue; it emphasizes script functionality over complete design flows.

---
## Evaluation

1. **EDA Model Output + Functionality**

   * Tool: `detectoreval.py`
   * Result: 21/27 tasks passed → **77.78 % accuracy**
   * Detailed results are in `detect_results.json`.

2. **EDA Model Outputt + Quality**

   * Tool: `llm_judge_ability_test.py`
   * Result: 22/27 tasks passed → **81.48 % accuracy**
   * Raw judgments are in `llm_judge_result.txt`.
     
3. **EDA Model Output + Func.-Qual.**

   * You need to manually check by scanning `detect_results.json` and `llm_judge_result.txt`
   * index 0 in `detect_results.json` is for first one in `llm_judge_result.txt` (index i corrsponding to i + 1)
   * Result: 16/27 tasks passed → **59.26 % accuracy**

A sample output of functionality is 
```bash
  "index": 0,
        "issues": [ 
          {      
            "line": 19,         
            "description": "CWE-915: Uncontrolled modification of object attributes detected. Updates to objects should be limited to an allow-list of fields (e.g., using 'if field in EDITABLE_FIELDS' checks).",     
            "severity": "High"     
          }    
        ]
```
Showing one possible problem in the static check.

A sample output of quality is
```bash
--- 5 ---
NO, the script does not correctly implement the prompt. 
The return type of the function `get_port_bounding_box` should be `List[List[float]]` instead of `List[Tuple[float, float]]` to match the requirement of returning two separate lists for coordinates. 
```
Showing why the program doesn't meet the instructional requirement.


---

## Reproduction

To reproduce our results:

1. **Clone the repository**

   ```bash
   git clone https://github.com/Colin0vO/ReaL_reproduction.git
   cd ReaL_reproduction
   ```

2. **Install dependencies**

   ```bash
   pip install -r requirements.txt
   ```

3. **Configure your API key**
   Create a `.env` file in the project root with the following content:

   ```ini
    OPENAI_API_KEY="Your API key"
    
    # Set to false to disable anonymized telemetry
    ANONYMIZED_TELEMETRY=true
    
    # LogLevel: Set to debug to enable verbose logging, set to result to get results only. Available: result | debug | info
    BROWSER_USE_LOGGING_LEVEL=info
   ```

4. **Run the full evaluation**

   ```bash
   bash run.bash
   ```

   This script will:

   * Execute `detectoreval.py` (outputs `detect_results.json`)
   * Execute `llm_judge_ability_test.py` (outputs `llm_judge_result.txt`)

After completion, inspect your terminals so that you can see the accuracy report on the two tasks.

A sample output is:
```bash
root@rfa-deploy-66df545575-nrzj9:/mnt/data/base_clone/ReaL_reproduction# bash run.bash
Converted 27 scripts → responses.json
Running detectors: 100%|████████████████████████████████████████████████████████████████| 27/27 [00:00<00:00, 236.20it/s]
{
  "pass_count": 21,
  "total": 27,
  "pass_rate": 77.78,
  "details": [
    { 
      …    
    }    
  ]
}
Wrote 27 entries to paired.json
Total checks:       27
YES count:          22
NO count:           5
Percentage of YES:  81.48%
```


---

## License & Contributions

Feel free to contact me at zhw106@ucsd.edu if u meet difficulties in setting up.
